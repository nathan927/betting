# docker-compose.yml - 生產級 Docker Compose 配置
version: '3.8'

services:
  # PostgreSQL with TimescaleDB
  timescaledb:
    image: timescale/timescaledb:latest-pg15
    container_name: betting-timescaledb
    restart: unless-stopped
    environment:
      POSTGRES_DB: betting_db
      POSTGRES_USER: betting_user
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      TIMESCALEDB_TELEMETRY: off
    secrets:
      - db_password
    volumes:
      - timescale_data:/var/lib/postgresql/data
      # Path to init_scripts relative to project root
      - ../../database/init_scripts/:/docker-entrypoint-initdb.d/
    ports:
      - "5432:5432"
    networks:
      - betting-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U betting_user -d betting_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # Redis
  redis:
    image: redis:7-alpine
    container_name: betting-redis
    restart: unless-stopped
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
    environment:
      REDIS_PASSWORD_FILE: /run/secrets/redis_password
    secrets:
      - redis_password
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - betting-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: betting-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: betting-kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: snappy
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "29092:29092"
    networks:
      - betting-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # Main API Server
  betting-api:
    build:
      context: ../../backend/services/api_gateway # Corrected path from project root
      dockerfile: Dockerfile # This is inside the api_gateway directory
      target: production
    container_name: betting-api
    restart: unless-stopped
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      NODE_ENV: production
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: betting_db
      DB_USER: betting_user
      REDIS_HOST: redis
      REDIS_PORT: 6379
      KAFKA_BROKERS: kafka:9092
      PORT: 3000
      WS_PORT: 8080
    secrets:
      - db_password
      - redis_password
      - jwt_secret
      - jwt_refresh_secret
      - encryption_key
    volumes:
      # Logs and uploads specific to api_gateway, path relative to project root
      - ../../backend/services/api_gateway/logs:/app/logs
      - ../../backend/services/api_gateway/uploads:/app/uploads
    ports:
      - "3000:3000"
      - "8080:8080"
    networks:
      - betting-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  # Arbitrage Detection Service
  arbitrage-engine:
    build:
      context: ../../backend/services/arbitrage_engine # Corrected path
      dockerfile: Dockerfile.arbitrage # This is inside the arbitrage_engine directory
    container_name: betting-arbitrage
    restart: unless-stopped
    depends_on:
      - kafka
      - redis
      - timescaledb
    environment:
      NODE_ENV: production
      DB_HOST: timescaledb
      REDIS_HOST: redis
      KAFKA_BROKERS: kafka:9092
    secrets:
      - db_password
      - redis_password
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Horse Racing ML Prediction Service
  horse-racing-ml:
    build:
      context: ../../ml_models/horse_racing # Corrected path
      dockerfile: Dockerfile.ml_horse_racing # This is inside the horse_racing directory
    container_name: betting-horse-racing-ml
    restart: unless-stopped
    depends_on:
      - timescaledb
      - redis
    environment:
      PYTHON_ENV: production
      DB_HOST: timescaledb # Service name from this docker-compose file
      REDIS_HOST: redis # Service name from this docker-compose file
      MODEL_PATH: /app/models # Standard path inside container
      APP_PORT: 5002 # Port the app inside the container runs on
    secrets: # Assuming ML service might need DB/Redis access
      - db_password
      - redis_password
    volumes:
      # Mount service-specific data and models
      - ../../ml_models/horse_racing/data:/app/data
      - ../../ml_models/horse_racing/saved_models:/app/models
    ports:
      - "5002:5002" # Expose port if directly accessible, or remove if only internal
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '2' # Adjust as needed
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G

  # Football ML Prediction Service
  football-ml:
    build:
      context: ../../ml_models/football # Corrected path
      dockerfile: Dockerfile.ml_football # This is inside the football directory
    container_name: betting-football-ml
    restart: unless-stopped
    depends_on:
      - timescaledb
      - redis
    environment:
      PYTHON_ENV: production
      DB_HOST: timescaledb
      REDIS_HOST: redis
      MODEL_PATH: /app/models
      APP_PORT: 5001 # Port the app inside the container runs on
    secrets:
      - db_password
      - redis_password
    volumes:
      - ../../ml_models/football/data:/app/data
      - ../../ml_models/football/saved_models:/app/models
    ports:
      - "5001:5001"
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G

  # Web Scraper Service
  scraper-service:
    build:
      context: ../../scrapers/bookmaker_scraper # Corrected path
      dockerfile: Dockerfile.scraper # This is inside the bookmaker_scraper directory
    container_name: betting-scraper
    restart: unless-stopped
    depends_on:
      - redis
      - kafka
    environment:
      PYTHON_ENV: production
      REDIS_HOST: redis
      KAFKA_BROKERS: kafka:9092
      HEADLESS: 'true'
    secrets:
      - redis_password
      # - proxy_credentials # Ensure this secret is defined below if used
    volumes:
      # Path to proxies.txt relative to project root
      - ../../scrapers/bookmaker_scraper/proxies.txt:/app/proxies.txt:ro
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # Monitoring Service
  monitoring:
    build:
      context: ../../backend/services/monitoring_service # Corrected path
      dockerfile: Dockerfile.monitoring # This is inside the monitoring_service directory
    container_name: betting-monitoring
    restart: unless-stopped
    depends_on:
      - timescaledb
      - redis
    environment:
      NODE_ENV: production
      DB_HOST: timescaledb
      REDIS_HOST: redis
      METRICS_PORT: 9090
    secrets:
      - db_password
      - redis_password
      - smtp_credentials
      - slack_token
    ports:
      - "9090:9090"
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: betting-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    volumes:
      # Path relative to deployment_configs/docker/ directory where this compose file is
      - ../prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9091:9090"
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: betting-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD__FILE: /run/secrets/grafana_password
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    secrets:
      - grafana_password
    volumes:
      # Path relative to deployment_configs/docker/ directory
      - grafana_data:/var/lib/grafana
      - ../grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "3001:3000"
    networks:
      - betting-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: betting-nginx
    restart: unless-stopped
    volumes:
      # Paths relative to deployment_configs/docker/ directory
      - ../nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../nginx/conf.d:/etc/nginx/conf.d:ro
      - ../ssl:/etc/nginx/ssl:ro # Assumes ssl certs are in deployment_configs/ssl
      - nginx_cache:/var/cache/nginx
    ports:
      - "80:80"
      - "443:443"
    networks:
      - betting-network
    depends_on:
      - betting-api
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M

# 網絡配置
networks:
  betting-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# 數據卷
volumes:
  timescale_data:
    driver: local
  redis_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  nginx_cache:
    driver: local

# 密鑰配置
secrets:
  db_password:
    external: true
  redis_password:
    external: true
  jwt_secret:
    external: true
  jwt_refresh_secret:
    external: true
  encryption_key:
    external: true
  grafana_password:
    external: true
  smtp_credentials:
    external: true
  slack_token:
    external: true
  proxy_credentials:
    external: true
